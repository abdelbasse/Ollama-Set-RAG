{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle API Setup Guide\n",
    "\n",
    "This guide explains how to set up the Kaggle API to use Python for downloading datasets.\n",
    "\n",
    "## Prerequisites\n",
    "- Ensure Python is installed on your system.\n",
    "- Install the Kaggle API package by running:\n",
    "  ```\n",
    "  pip install kaggle\n",
    "  ```\n",
    "\n",
    "## Setting Up `kaggle.json`\n",
    "The `kaggle.json` file contains your API key, which is required to authenticate with Kaggle.\n",
    "\n",
    "### Step 1: Download `kaggle.json`\n",
    "1. Log in to your [Kaggle account settings](https://www.kaggle.com/account).\n",
    "2. Scroll to the **API** section.\n",
    "3. Click **Create New API Token**. This will download a file named `kaggle.json`.\n",
    "\n",
    "### Step 2: Place the `kaggle.json` File\n",
    "1. Create a `.kaggle` directory in your user home directory:\n",
    "   - On Windows: `C:\\Users\\YourUsername\\.kaggle`\n",
    "   - On Mac/Linux: `~/.kaggle`\n",
    "\n",
    "2. Move the `kaggle.json` file to the `.kaggle` directory.\n",
    "\n",
    "### Step 3: Verify Permissions (Optional for Windows)\n",
    "- On Linux/Mac, set the correct permissions to secure the file:\n",
    "  ```\n",
    "  chmod 600 ~/.kaggle/kaggle.json\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset 'simiotic/github-code-snippets'...\n",
      "Dataset URL: https://www.kaggle.com/datasets/simiotic/github-code-snippets\n",
      "Dataset downloaded and extracted to: /root/Ollama-Set-RAG/datasets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Initialize and authenticate the Kaggle API\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Specify the dataset to download\n",
    "dataset_name = \"simiotic/github-code-snippets\"  # Replace with your desired dataset\n",
    "\n",
    "# Define the path to download the dataset\n",
    "download_path = \"./datasets\"\n",
    "\n",
    "# Download the dataset\n",
    "print(f\"Downloading dataset '{dataset_name}'...\")\n",
    "api.dataset_download_files(dataset_name, path=download_path, unzip=True)\n",
    "print(f\"Dataset downloaded and extracted to: {os.path.abspath(download_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the data of this `.db` file\n",
    "### Step 1: Download `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting numpy>=1.26.0 (from pandas)\n",
      "  Downloading numpy-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./RagDataSetup/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./RagDataSetup/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m120.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.0 pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Show the data\n",
    "Since your dataset is located in the ./datasets/snippets/ directory and you have a file named snippets.db, it seems like the dataset might be in an SQLite database format. You can use Python to load the data from the snippets.db file using the sqlite3 library in Python.\n",
    "\n",
    "Here's how you can access the data from the snippets.db SQLite database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      language  total_chunk_size\n",
      "0         Bash             53840\n",
      "1            C          61905695\n",
      "2          C++          32807530\n",
      "3          CSV            888775\n",
      "4      DOTFILE            337085\n",
      "5           Go          40669595\n",
      "6         HTML           9936365\n",
      "7         JSON          32576945\n",
      "8         Java          37707120\n",
      "9   JavaScript          45340285\n",
      "10     Jupyter           1229605\n",
      "11    Markdown          14949355\n",
      "12  PowerShell            195980\n",
      "13      Python          19833355\n",
      "14        Ruby           5435615\n",
      "15        Rust           2993515\n",
      "16       Shell           1923690\n",
      "17         TSV             51525\n",
      "18        Text          17147775\n",
      "19     UNKNOWN         158415145\n",
      "20        YAML           2938680\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the SQLite database\n",
    "database_path = \"./datasets/snippets/snippets.db\"\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(database_path)\n",
    "\n",
    "# Query to select all columns from the 'snippets' table\n",
    "query = \"SELECT language, SUM(chunk_size) AS total_chunk_size FROM snippets GROUP BY language\"  # You can adjust the LIMIT as needed\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "# Display the DataFrame as a table\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "To filter the Java-related snippets from your large database and save them in a more accessible format, here's the plan:\n",
    "\n",
    "1. **Filter Java-related Snippets**: You'll extract only the rows where the `language` is \"Java\".\n",
    "2. **Export to an Efficient Format**: Save the filtered data in a format that is easy to read and process, such as **CSV** or **Parquet**, as both formats are fast to load and can be used for future analysis or requests.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Filter the Data**: Query the database for all Java-related snippets.\n",
    "2. **Export the Filtered Data**: Save the filtered snippets to a file (either CSV or Parquet).\n",
    "3. **Load and Work with the Data**: You can later load this file into pandas or any other tool for further processing.\n",
    "\n",
    "### 1. Python Code to Filter Java Snippets and Export to CSV or Parquet:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java-related snippets exported to 'javaSnippets.csv'\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the SQLite database\n",
    "database_path = \"./datasets/snippets/snippets.db\"\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(database_path)\n",
    "\n",
    "# Query to filter Java-related snippets\n",
    "query = \"\"\"\n",
    "    SELECT * FROM snippets\n",
    "    WHERE language = 'Java'\n",
    "\"\"\"\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df_java = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Export the filtered data to CSV (or use Parquet for more efficient storage)\n",
    "df_java.to_csv(\"./datasets/snippets/javaSnippets.csv\", index=False)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()\n",
    "\n",
    "print(\"Java-related snippets exported to 'javaSnippets.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Explanation of the Code:\n",
    "\n",
    "- **Database Connection**: We open a connection to the `snippets.db` database using `sqlite3`.\n",
    "- **SQL Query**: We query the `snippets` table to select only those rows where the `language` is \"Java\".\n",
    "- **Exporting**: We save the filtered data to a **CSV** file (`javaSnippets.csv`) or **Parquet** file. You can choose which format works best for you. CSV is human-readable, while Parquet is more efficient for large datasets.\n",
    "- **Close the Connection**: The database connection is closed once the export is complete.\n",
    "\n",
    "### 3. Loading the Exported Data:\n",
    "\n",
    "Once you’ve exported the data to a file, you can easily load it back into pandas for any further analysis.\n",
    "\n",
    "#### Loading the CSV File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>snippet</th>\n",
       "      <th>language</th>\n",
       "      <th>repo_file_name</th>\n",
       "      <th>github_repo_url</th>\n",
       "      <th>license</th>\n",
       "      <th>commit_hash</th>\n",
       "      <th>starting_line_number</th>\n",
       "      <th>chunk_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88608</td>\n",
       "      <td>/*\\n * Copyright 2014 The Netty Project\\n *\\n ...</td>\n",
       "      <td>Java</td>\n",
       "      <td>netty/netty/resolver-dns/src/test/java/io/nett...</td>\n",
       "      <td>https://github.com/netty/netty</td>\n",
       "      <td>Apache-2.0</td>\n",
       "      <td>a60825c3b425892af9be3e9284677aa8a58faa6b\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88609</td>\n",
       "      <td>* with the License. You may obtain a copy of ...</td>\n",
       "      <td>Java</td>\n",
       "      <td>netty/netty/resolver-dns/src/test/java/io/nett...</td>\n",
       "      <td>https://github.com/netty/netty</td>\n",
       "      <td>Apache-2.0</td>\n",
       "      <td>a60825c3b425892af9be3e9284677aa8a58faa6b\\n</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88610</td>\n",
       "      <td>* distributed under the License is distribute...</td>\n",
       "      <td>Java</td>\n",
       "      <td>netty/netty/resolver-dns/src/test/java/io/nett...</td>\n",
       "      <td>https://github.com/netty/netty</td>\n",
       "      <td>Apache-2.0</td>\n",
       "      <td>a60825c3b425892af9be3e9284677aa8a58faa6b\\n</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88611</td>\n",
       "      <td>\\npackage io.netty.resolver.dns;\\n\\nimport io....</td>\n",
       "      <td>Java</td>\n",
       "      <td>netty/netty/resolver-dns/src/test/java/io/nett...</td>\n",
       "      <td>https://github.com/netty/netty</td>\n",
       "      <td>Apache-2.0</td>\n",
       "      <td>a60825c3b425892af9be3e9284677aa8a58faa6b\\n</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88612</td>\n",
       "      <td>\\nimport java.net.InetSocketAddress;\\nimport j...</td>\n",
       "      <td>Java</td>\n",
       "      <td>netty/netty/resolver-dns/src/test/java/io/nett...</td>\n",
       "      <td>https://github.com/netty/netty</td>\n",
       "      <td>Apache-2.0</td>\n",
       "      <td>a60825c3b425892af9be3e9284677aa8a58faa6b\\n</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                            snippet language  \\\n",
       "0  88608  /*\\n * Copyright 2014 The Netty Project\\n *\\n ...     Java   \n",
       "1  88609   * with the License. You may obtain a copy of ...     Java   \n",
       "2  88610   * distributed under the License is distribute...     Java   \n",
       "3  88611  \\npackage io.netty.resolver.dns;\\n\\nimport io....     Java   \n",
       "4  88612  \\nimport java.net.InetSocketAddress;\\nimport j...     Java   \n",
       "\n",
       "                                      repo_file_name  \\\n",
       "0  netty/netty/resolver-dns/src/test/java/io/nett...   \n",
       "1  netty/netty/resolver-dns/src/test/java/io/nett...   \n",
       "2  netty/netty/resolver-dns/src/test/java/io/nett...   \n",
       "3  netty/netty/resolver-dns/src/test/java/io/nett...   \n",
       "4  netty/netty/resolver-dns/src/test/java/io/nett...   \n",
       "\n",
       "                  github_repo_url     license  \\\n",
       "0  https://github.com/netty/netty  Apache-2.0   \n",
       "1  https://github.com/netty/netty  Apache-2.0   \n",
       "2  https://github.com/netty/netty  Apache-2.0   \n",
       "3  https://github.com/netty/netty  Apache-2.0   \n",
       "4  https://github.com/netty/netty  Apache-2.0   \n",
       "\n",
       "                                  commit_hash  starting_line_number  \\\n",
       "0  a60825c3b425892af9be3e9284677aa8a58faa6b\\n                     0   \n",
       "1  a60825c3b425892af9be3e9284677aa8a58faa6b\\n                     5   \n",
       "2  a60825c3b425892af9be3e9284677aa8a58faa6b\\n                    10   \n",
       "3  a60825c3b425892af9be3e9284677aa8a58faa6b\\n                    15   \n",
       "4  a60825c3b425892af9be3e9284677aa8a58faa6b\\n                    20   \n",
       "\n",
       "   chunk_size  \n",
       "0           5  \n",
       "1           5  \n",
       "2           5  \n",
       "3           5  \n",
       "4           5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Java snippets CSV file\n",
    "df_java = pd.read_csv(\"./datasets/snippets/javaSnippets.csv\")\n",
    "\n",
    "# Display the first few rows of the data\n",
    "df_java.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Benefits of This Approach:\n",
    "\n",
    "- **Speed**: Exporting the Java-related snippets to a file format like CSV or Parquet will make it faster to load and query in the future, avoiding the overhead of querying a large SQLite database.\n",
    "- **Ease of Use**: You can use pandas or other tools to read the file and easily filter, analyze, or manipulate the data.\n",
    "- **Efficient Storage**: Parquet is more space-efficient and faster for reading large datasets compared to CSV.\n",
    "\n",
    "This approach should help you manage large datasets effectively and focus on Java snippets for debugging and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm './datasets/snippets/snippets.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s how you can write Python code to split a large file into two smaller files, and then combine them back into the original file:\n",
    "\n",
    "### Split the large file into two parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3304296322.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    import ospath = './datasets/snippets/'\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def split_file(input_file, part_prefix, max_size=100 * 1024 * 1024):\n",
    "    with open(input_file, 'rb') as file:\n",
    "        part_number = 1\n",
    "        while True:\n",
    "            # Read up to `max_size` bytes\n",
    "            data = file.read(max_size)\n",
    "            if not data:  # Stop if no more data to read\n",
    "                break\n",
    "            \n",
    "            # Format the output file name: <part_prefix>_part<part_number>.csv\n",
    "            part_file = f\"{part_prefix}_part{part_number}.csv\"\n",
    "            with open(part_file, 'wb') as output:\n",
    "                output.write(data)\n",
    "            \n",
    "            print(f\"Created {part_file}\")\n",
    "            part_number += 1\n",
    "\n",
    "    os.remove(input_file)  # Remove the original file\n",
    "    print(f\"Original file {input_file} removed after splitting.\")\n",
    "\n",
    "# Example usage\n",
    "path = './datasets/snippets/'\n",
    "input_file = f'{path}javaSnippets.csv'\n",
    "part_prefix = f'{path}javaSnippets'  # Prefix for output parts\n",
    "\n",
    "split_file(input_file, part_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the two smaller files back into the original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files combined into ./datasets/snippets/javaSnippets.csv\n"
     ]
    }
   ],
   "source": [
    "def combine_files(part_prefix, output_file):\n",
    "    part_number = 1\n",
    "    with open(output_file, 'wb') as output:\n",
    "        while True:\n",
    "            # Generate part file name: <part_prefix>_part<part_number>.csv\n",
    "            part_file = f\"{part_prefix}_part{part_number}.csv\"\n",
    "            \n",
    "            if not os.path.exists(part_file):\n",
    "                # Stop if the part file doesn't exist\n",
    "                break\n",
    "            \n",
    "            # Combine the part file into the output file\n",
    "            with open(part_file, 'rb') as part:\n",
    "                output.write(part.read())\n",
    "            \n",
    "            # Remove the part file after combining\n",
    "            os.remove(part_file)\n",
    "            print(f\"Added {part_file} to {output_file} and removed it.\")\n",
    "            part_number += 1\n",
    "\n",
    "    print(f\"Files combined into {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "output_file = f'{path}javaSnippets.csv'\n",
    "\n",
    "combine_files(part_prefix, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the code works:\n",
    "1. **Splitting**: \n",
    "   - The `split_file` function reads the entire input file as binary (`'rb'` mode).\n",
    "   - It splits the data into two parts using the midpoint (half of the file size).\n",
    "   - It writes the first half to `output_file1` and the second half to `output_file2`.\n",
    "\n",
    "2. **Combining**:\n",
    "   - The `combine_files` function opens both smaller files (`input_file1` and `input_file2`) and writes their contents into `output_file`.\n",
    "   - The files are opened in binary mode (`'rb'` and `'wb'`) to handle any file type, including large files.\n",
    "\n",
    "### Notes:\n",
    "- Replace `'path_to_large_file/javaSnippets.csv'`, `'path_to_large_file/javaSnippets_part1.csv'`, etc., with the actual paths of your files.\n",
    "- Make sure the file you want to split is not open in another program, as this might cause a permission error.\n",
    "\n",
    "Let me know if you need further assistance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp './datasets/snippets/javaSnippets.csv' './datasets/snippets/Storage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
